{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prototype a web scraper for Penny Acade news posts. I want to assemble a dataset so that I can later train a language model based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import sqlite3\n",
    "import time\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to iterate through each news post. The structure of the URL is as follows:\n",
    "\n",
    "`https://www.penny-arcade.com/news/post/2023/03/03/moisture-farm`\n",
    "\n",
    "The first part of the URL is constant. The second part is the year, the third part is the month, and the fourth part is the day. \n",
    "\n",
    "If you input just the date (e.g. `https://www.penny-arcade.com/news/post/2023/03/03/`), it will provide the full URL for the post. We can use this fact and the datetime library to iterate through without having to manually determine each URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date\n",
       "0  2005-01-01\n",
       "1  2005-01-02\n",
       "2  2005-01-03\n",
       "3  2005-01-04\n",
       "4  2005-01-05"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start_date = datetime.date(1998, 11, 18)\n",
    "# end_date = datetime.date(2023, 3, 3)\n",
    "\n",
    "start_date = datetime.date(2005, 1, 1)\n",
    "end_date = datetime.date(2023, 3, 3)\n",
    "\n",
    "delta = datetime.timedelta(days=1)\n",
    "\n",
    "dates = pd.DataFrame()\n",
    "while start_date <= end_date:\n",
    "    dates = pd.concat([dates, pd.DataFrame({'date': [start_date]})])\n",
    "    start_date += delta\n",
    "\n",
    "dates = dates.reset_index(drop=True)\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of urls\n",
    "# e.g. https://www.penny-arcade.com/news/post/2023/03/03/\n",
    "urls = []\n",
    "for row in range(len(dates)):\n",
    "    date = dates['date'][row].strftime('%Y-%m-%d').split('-')\n",
    "\n",
    "    year = date[0]\n",
    "    month = date[1].zfill(2)\n",
    "    day = date[2].zfill(2)\n",
    "    urls.append(f'https://www.penny-arcade.com/news/post/{year}/{month}/{day}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sqlite database\n",
    "conn = sqlite3.connect('penny_arcade.db')\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS posts\n",
    "                (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                date TEXT,\n",
    "                title TEXT,\n",
    "                text TEXT,\n",
    "                author TEXT,\n",
    "                tags TEXT,\n",
    "                comic TEXT)''')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('penny_arcade.db')\n",
    "\n",
    "# test_urls = ['https://www.penny-arcade.com/news/post/1998/11/19/','https://www.penny-arcade.com/news/post/2023/03/03/']\n",
    "\n",
    "# iterate over each url\n",
    "for url in urls:\n",
    "# for url in test_urls:\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    if soup.find('main', {'id': 'main', 'class': 'error-page'}):\n",
    "        # print(f'{url} is not a valid date')\n",
    "        continue\n",
    "    \n",
    "    # get the date from the url\n",
    "    # date = url.split('/')[-2:]\n",
    "    match = re.search(r'/(\\d{4})/(\\d{2})/(\\d{2})/', url)\n",
    "    date = match.group(1) + '-' + match.group(2) + '-' + match.group(3)\n",
    "\n",
    "    # get the title\n",
    "    # it will be an h1 that comes after <p class=\"details date\">\n",
    "    title = soup.find('p', {'class': 'details date'}).find_next('h1').text\n",
    "\n",
    "    # get the text\n",
    "    # look for <section class=\"post-text\">\n",
    "    # then look for <p> tags inside of that\n",
    "    # there can be multiple <p> tags and multiple <section> tags\n",
    "    # so we need to iterate over each <section> tag\n",
    "    # and then iterate over each <p> tag\n",
    "    text = ''\n",
    "    for section in soup.find_all('section', {'class': 'post-text'}):\n",
    "        for p in section.find_all('p'):\n",
    "            text += p.text\n",
    "            text += '\\n'\n",
    "\n",
    "    # get the author\n",
    "    # look for <p class=\"details author\">\n",
    "    author = soup.find('p', {'class': 'details author'}).text\n",
    "    author = author[3:] # remove the 'by ' from the beginning\n",
    "    if author == 'Tycho':\n",
    "        author = 'Tycho Brahe'\n",
    "    elif author == 'Gabe':\n",
    "        author = 'Johnathan Gabriel'\n",
    "\n",
    "    # get the tags\n",
    "    # look for <ul class=\"tags\">\n",
    "    # then look for <li> tags inside of that\n",
    "    # there can be multiple <li> tags\n",
    "    # so we need to iterate over each <li> tag\n",
    "    tags = ''\n",
    "    for li in soup.find('ul', {'class': 'tags'}).find_all('li'):\n",
    "        tags += li.text\n",
    "        tags += ', ' if li != soup.find('ul', {'class': 'tags'}).find_all('li')[-1] else ''\n",
    "\n",
    "    # get the associated comic url\n",
    "    # we can simply transform the url to get the comic url\n",
    "    # e.g. https://www.penny-arcade.com/news/post/2023/03/03/\n",
    "    # becomes https://www.penny-arcade.com/comic/2023/03/03/\n",
    "    comic = url.replace('news/post', 'comic')   \n",
    "\n",
    "    # print the data\n",
    "    # print(f'date: {date}')\n",
    "    # print(f'title: {title}')\n",
    "    # print(f'text: {text}')\n",
    "    # print(f'author: {author}')\n",
    "    # print(f'tags: {tags}')\n",
    "    # print(f'comic: {comic}')\n",
    "\n",
    "    # insert the data into the database\n",
    "    conn.execute('''INSERT INTO posts (date, title, text, author, tags, comic)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?)''', (date, title, text, author, tags, comic))\n",
    "    conn.commit()\n",
    "\n",
    "    # wait  a random amount of time between 0.5 and 3 seconds\n",
    "    # helps avoid getting blocked by the website\n",
    "    time.sleep(random.uniform(0.5, 2))\n",
    "\n",
    "conn.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "      <th>comic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>3832</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>In The Cards</td>\n",
       "      <td>I think that I initially thought of it as a jo...</td>\n",
       "      <td>Tycho Brahe</td>\n",
       "      <td>Magic: The Gathering, Gideon Jura, Hot Pockets</td>\n",
       "      <td>https://www.penny-arcade.com/comic/2023/02/22/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>3833</td>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>Zombawomba</td>\n",
       "      <td>It turns out that Gabe is fucking obsessed wit...</td>\n",
       "      <td>Tycho Brahe</td>\n",
       "      <td>Gran Turismo, Hi-Fi Rush, PSVR2, Resident Evil</td>\n",
       "      <td>https://www.penny-arcade.com/comic/2023/02/24/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>3834</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>My Favorite PSVR2 Games!</td>\n",
       "      <td>I’ve spent the last 6 days putting the PSVR2 t...</td>\n",
       "      <td>Johnathan Gabriel</td>\n",
       "      <td>Playstation VR</td>\n",
       "      <td>https://www.penny-arcade.com/comic/2023/02/27/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>3835</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>Gabriel The Younger</td>\n",
       "      <td>It's true! Gabriel The Younger has been accept...</td>\n",
       "      <td>Tycho Brahe</td>\n",
       "      <td>DigiPen, Gabriel the Younger</td>\n",
       "      <td>https://www.penny-arcade.com/comic/2023/03/01/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>3836</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>Moisture Farm</td>\n",
       "      <td>My existing VR headsets have always had some k...</td>\n",
       "      <td>Tycho Brahe</td>\n",
       "      <td>PSVR2, Moisture</td>\n",
       "      <td>https://www.penny-arcade.com/comic/2023/03/03/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date                     title  \\\n",
       "3831  3832  2023-02-22              In The Cards   \n",
       "3832  3833  2023-02-24                Zombawomba   \n",
       "3833  3834  2023-02-27  My Favorite PSVR2 Games!   \n",
       "3834  3835  2023-03-01       Gabriel The Younger   \n",
       "3835  3836  2023-03-03             Moisture Farm   \n",
       "\n",
       "                                                   text             author  \\\n",
       "3831  I think that I initially thought of it as a jo...        Tycho Brahe   \n",
       "3832  It turns out that Gabe is fucking obsessed wit...        Tycho Brahe   \n",
       "3833  I’ve spent the last 6 days putting the PSVR2 t...  Johnathan Gabriel   \n",
       "3834  It's true! Gabriel The Younger has been accept...        Tycho Brahe   \n",
       "3835  My existing VR headsets have always had some k...        Tycho Brahe   \n",
       "\n",
       "                                                tags  \\\n",
       "3831  Magic: The Gathering, Gideon Jura, Hot Pockets   \n",
       "3832  Gran Turismo, Hi-Fi Rush, PSVR2, Resident Evil   \n",
       "3833                                  Playstation VR   \n",
       "3834                    DigiPen, Gabriel the Younger   \n",
       "3835                                 PSVR2, Moisture   \n",
       "\n",
       "                                               comic  \n",
       "3831  https://www.penny-arcade.com/comic/2023/02/22/  \n",
       "3832  https://www.penny-arcade.com/comic/2023/02/24/  \n",
       "3833  https://www.penny-arcade.com/comic/2023/02/27/  \n",
       "3834  https://www.penny-arcade.com/comic/2023/03/01/  \n",
       "3835  https://www.penny-arcade.com/comic/2023/03/03/  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the data\n",
    "conn = sqlite3.connect('penny_arcade.db')\n",
    "table = pd.read_sql_query('SELECT * FROM posts', conn)\n",
    "\n",
    "conn.close()\n",
    "table.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
