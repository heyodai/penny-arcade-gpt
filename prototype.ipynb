{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prototype a web scraper for Penny Acade news posts. I want to assemble a dataset so that I can later train a language model based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import sqlite3\n",
    "import time\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to iterate through each news post. The structure of the URL is as follows:\n",
    "\n",
    "`https://www.penny-arcade.com/news/post/2023/03/03/moisture-farm`\n",
    "\n",
    "The first part of the URL is constant. The second part is the year, the third part is the month, and the fourth part is the day. \n",
    "\n",
    "If you input just the date (e.g. `https://www.penny-arcade.com/news/post/2023/03/03/`), it will provide the full URL for the post. We can use this fact and the datetime library to iterate through without having to manually determine each URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date\n",
       "0  2004-01-01\n",
       "1  2004-01-02\n",
       "2  2004-01-03\n",
       "3  2004-01-04\n",
       "4  2004-01-05"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start_date = datetime.date(1998, 11, 18)\n",
    "# end_date = datetime.date(2023, 3, 3)\n",
    "\n",
    "start_date = datetime.date(2005, 1, 1)\n",
    "end_date = datetime.date(2023, 3, 3)\n",
    "\n",
    "delta = datetime.timedelta(days=1)\n",
    "\n",
    "dates = pd.DataFrame()\n",
    "while start_date <= end_date:\n",
    "    dates = pd.concat([dates, pd.DataFrame({'date': [start_date]})])\n",
    "    start_date += delta\n",
    "\n",
    "dates = dates.reset_index(drop=True)\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of urls\n",
    "# e.g. https://www.penny-arcade.com/news/post/2023/03/03/\n",
    "urls = []\n",
    "for row in range(len(dates)):\n",
    "    date = dates['date'][row].strftime('%Y-%m-%d').split('-')\n",
    "\n",
    "    year = date[0]\n",
    "    month = date[1].zfill(2)\n",
    "    day = date[2].zfill(2)\n",
    "    urls.append(f'https://www.penny-arcade.com/news/post/{year}/{month}/{day}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sqlite database\n",
    "conn = sqlite3.connect('penny_arcade.db')\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS posts\n",
    "                (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                date TEXT,\n",
    "                title TEXT,\n",
    "                text TEXT,\n",
    "                author TEXT,\n",
    "                tags TEXT,\n",
    "                comic TEXT)''')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('penny_arcade.db')\n",
    "\n",
    "# test_urls = ['https://www.penny-arcade.com/news/post/1998/11/19/','https://www.penny-arcade.com/news/post/2023/03/03/']\n",
    "\n",
    "# iterate over each url\n",
    "for url in urls:\n",
    "# for url in test_urls:\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    if soup.find('main', {'id': 'main', 'class': 'error-page'}):\n",
    "        # print(f'{url} is not a valid date')\n",
    "        continue\n",
    "    \n",
    "    # get the date from the url\n",
    "    # date = url.split('/')[-2:]\n",
    "    match = re.search(r'/(\\d{4})/(\\d{2})/(\\d{2})/', url)\n",
    "    date = match.group(1) + '-' + match.group(2) + '-' + match.group(3)\n",
    "\n",
    "    # get the title\n",
    "    # it will be an h1 that comes after <p class=\"details date\">\n",
    "    title = soup.find('p', {'class': 'details date'}).find_next('h1').text\n",
    "\n",
    "    # get the text\n",
    "    # look for <section class=\"post-text\">\n",
    "    # then look for <p> tags inside of that\n",
    "    # there can be multiple <p> tags and multiple <section> tags\n",
    "    # so we need to iterate over each <section> tag\n",
    "    # and then iterate over each <p> tag\n",
    "    text = ''\n",
    "    for section in soup.find_all('section', {'class': 'post-text'}):\n",
    "        for p in section.find_all('p'):\n",
    "            text += p.text\n",
    "            text += '\\n'\n",
    "\n",
    "    # get the author\n",
    "    # look for <p class=\"details author\">\n",
    "    author = soup.find('p', {'class': 'details author'}).text\n",
    "    author = author[3:] # remove the 'by ' from the beginning\n",
    "    if author == 'Tycho':\n",
    "        author = 'Tycho Brahe'\n",
    "    elif author == 'Gabe':\n",
    "        author = 'Johnathan Gabriel'\n",
    "\n",
    "    # get the tags\n",
    "    # look for <ul class=\"tags\">\n",
    "    # then look for <li> tags inside of that\n",
    "    # there can be multiple <li> tags\n",
    "    # so we need to iterate over each <li> tag\n",
    "    tags = ''\n",
    "    for li in soup.find('ul', {'class': 'tags'}).find_all('li'):\n",
    "        tags += li.text\n",
    "        tags += ', ' if li != soup.find('ul', {'class': 'tags'}).find_all('li')[-1] else ''\n",
    "\n",
    "    # get the associated comic url\n",
    "    # we can simply transform the url to get the comic url\n",
    "    # e.g. https://www.penny-arcade.com/news/post/2023/03/03/\n",
    "    # becomes https://www.penny-arcade.com/comic/2023/03/03/\n",
    "    comic = url.replace('news/post', 'comic')   \n",
    "\n",
    "    # print the data\n",
    "    # print(f'date: {date}')\n",
    "    # print(f'title: {title}')\n",
    "    # print(f'text: {text}')\n",
    "    # print(f'author: {author}')\n",
    "    # print(f'tags: {tags}')\n",
    "    # print(f'comic: {comic}')\n",
    "\n",
    "    # insert the data into the database\n",
    "    conn.execute('''INSERT INTO posts (date, title, text, author, tags, comic)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?)''', (date, title, text, author, tags, comic))\n",
    "    conn.commit()\n",
    "\n",
    "    # wait  a random amount of time between 0.5 and 3 seconds\n",
    "    # helps avoid getting blocked by the website\n",
    "    time.sleep(random.uniform(0.5, 2))\n",
    "\n",
    "conn.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "      <th>comic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>476</td>\n",
       "      <td>2004-12-24</td>\n",
       "      <td>The Last Christmas, Page Four</td>\n",
       "      <td>This season's presentation of The Last Christm...</td>\n",
       "      <td>Tycho Brahe</td>\n",
       "      <td></td>\n",
       "      <td>https://www.penny-arcade.com/comic/2004/12/24/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>477</td>\n",
       "      <td>2004-12-27</td>\n",
       "      <td>The Last Christmas, Page Five</td>\n",
       "      <td>\\nThe Last Christmas cycle is now complete.  I...</td>\n",
       "      <td>Tycho Brahe</td>\n",
       "      <td></td>\n",
       "      <td>https://www.penny-arcade.com/comic/2004/12/27/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>478</td>\n",
       "      <td>2004-12-28</td>\n",
       "      <td>Brothers In Arms</td>\n",
       "      <td>\\nWe had the opportunity to do something reall...</td>\n",
       "      <td>Johnathan Gabriel</td>\n",
       "      <td></td>\n",
       "      <td>https://www.penny-arcade.com/comic/2004/12/28/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>479</td>\n",
       "      <td>2004-12-29</td>\n",
       "      <td>The Sony Syndrome, Final</td>\n",
       "      <td>\\nGod dammit, we couldn't resist capping that ...</td>\n",
       "      <td>Tycho Brahe</td>\n",
       "      <td></td>\n",
       "      <td>https://www.penny-arcade.com/comic/2004/12/29/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>480</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>A Being Of Indescribable Power</td>\n",
       "      <td>\\nIt was idle speculation when, a couple years...</td>\n",
       "      <td>Tycho Brahe</td>\n",
       "      <td></td>\n",
       "      <td>https://www.penny-arcade.com/comic/2004/12/31/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        date                           title  \\\n",
       "475  476  2004-12-24   The Last Christmas, Page Four   \n",
       "476  477  2004-12-27   The Last Christmas, Page Five   \n",
       "477  478  2004-12-28                Brothers In Arms   \n",
       "478  479  2004-12-29        The Sony Syndrome, Final   \n",
       "479  480  2004-12-31  A Being Of Indescribable Power   \n",
       "\n",
       "                                                  text             author  \\\n",
       "475  This season's presentation of The Last Christm...        Tycho Brahe   \n",
       "476  \\nThe Last Christmas cycle is now complete.  I...        Tycho Brahe   \n",
       "477  \\nWe had the opportunity to do something reall...  Johnathan Gabriel   \n",
       "478  \\nGod dammit, we couldn't resist capping that ...        Tycho Brahe   \n",
       "479  \\nIt was idle speculation when, a couple years...        Tycho Brahe   \n",
       "\n",
       "    tags                                           comic  \n",
       "475       https://www.penny-arcade.com/comic/2004/12/24/  \n",
       "476       https://www.penny-arcade.com/comic/2004/12/27/  \n",
       "477       https://www.penny-arcade.com/comic/2004/12/28/  \n",
       "478       https://www.penny-arcade.com/comic/2004/12/29/  \n",
       "479       https://www.penny-arcade.com/comic/2004/12/31/  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the data\n",
    "conn = sqlite3.connect('penny_arcade.db')\n",
    "table = pd.read_sql_query('SELECT * FROM posts', conn)\n",
    "\n",
    "conn.close()\n",
    "table.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
